# 基本信息

论文：Fully Convolutional Networks for Semantic Segmentation

发表：2015CVPR

# 网络结构

![descript](./FCN（全卷积网络）/media/image1.png){width="4.78125in"
height="2.2886253280839894in"}

FCN可以接受任意尺寸的输入图像，采用反卷积层对最后一个卷积层的feature
map进行上采样, 恢复到输入图像尺寸，从而可以对每个像素都产生一个预测,
最后在上采样的特征图上进行逐像素分类。

计算Loss时需要计算每个像素Softmax分类的损失,
相当于每一个像素为一个训练样本。

![descript](./FCN（全卷积网络）/media/image2.png){width="6.299305555555556in"
height="1.6802919947506563in"}

# 网络性能

FCN-8s比SoTA准确率（mean IU）提升20%（基于PASCAL
VOC2011和VOC2012测试集）

推理时间大幅减少（\~50s减少到\~175ms）

# 创新点

## convolutionalization

FCN中所有层都是卷积层，FCN与CNN的区别在于把CNN最后的全连接层换成卷积层。

### 传统 CNN 缺点

1.  存储开销大，滑动窗口较大，每个窗口都需要存储空间来保存特征和判别类别，而且使用全连接结构，最后几层将近指数级存储递增

2.  计算效率低，大量重复计算，相邻像素块的内容较重复，每个像素块逐个计算卷积有很大程度的重复

3.  滑动窗口大小是相对独立的，末端使用全连接只能约束局部特征。

![descript](./FCN（全卷积网络）/media/image3.png){width="4.791666666666667in"
height="2.7919444444444443in"}

**传统的基于CNN的分割方法**：为了对一个像素分类，使用该像素周围的一个图像块作为CNN的输入用于训练和预测。这种方法有几个缺点：一是存储开销很大。例如对每个像素使用的图像块的大小为15x15，然后不断滑动窗口，每次滑动的窗口给CNN进行判别分类，因此则所需的存储空间根据滑动窗口的次数和大小急剧上升。二是计算效率低下。相邻的像素块基本上是重复的，针对每个像素块逐个计算卷积，这种计算也有很大程度上的重复。三是像素块大小的限制了感知区域的大小。通常像素块的大小比整幅图像的大小小很多，只能提取一些局部的特征，从而导致分类的性能受到限制。![descript](./FCN（全卷积网络）/media/image4.jpg){width="6.299305555555556in"
height="3.2375240594925634in"}![descript](./FCN（全卷积网络）/media/image5.jpg){width="6.299305555555556in"
height="3.2375240594925634in"}![descript](./FCN（全卷积网络）/media/image6.jpg){width="6.299305555555556in"
height="3.2375240594925634in"}
